{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tests import en_test_inputs, fr_test_ins, it_test_ins, lv_test_ins\n",
    "import re\n",
    "%matplotlib inline\n",
    "\n",
    "languages = [\n",
    "    'sv', 'da', 'de', 'nl', 'en', 'fr', 'es', 'pt', 'it', 'ro', 'et',\n",
    "    'fi','lt', 'lv', 'pl', 'sk', 'cs', 'sl', 'hu', 'bg',  'el'\n",
    "]\n",
    "\n",
    "files = [\n",
    "    \"train/europarl-v7.{lang}-en.{lang}\".format(lang=x)\n",
    "    for x in languages\n",
    "]\n",
    "\n",
    "corpus_raw = [\n",
    "    open(x).read(1500000) for x in files\n",
    "]\n",
    "\n",
    "corpus = [\n",
    "    re.sub(r'[?”_\"%()!--+,:;./\\]\\[\\xad\\n0-9\\=<>]', '', x) for x in corpus_raw\n",
    "]\n",
    "\n",
    "zeros = np.zeros(len(languages))\n",
    "\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(ngram_range=(4, 4), analyzer='char_wb')\n",
    "analyze = count_vectorizer.build_analyzer()\n",
    "counts = count_vectorizer.fit_transform(corpus)\n",
    "\n",
    "a = np.array(counts.todense().tolist())\n",
    "a = a/a.sum(axis=0)\n",
    "counts = np.cbrt(a)\n",
    "transformed_weights = a/a.sum(axis=1)\n",
    "\n",
    "#counts.data = counts.data ** 0.4\n",
    "#tfidf_transformer = TfidfTransformer(smooth_idf=False, sublinear_tf=False, use_idf=False)\n",
    "#transformed_weights = tfidf_transformer.fit_transform(counts)\n",
    "\n",
    "three_gram_to_index = dict(zip(count_vectorizer.get_feature_names(), range(len(count_vectorizer.get_feature_names()))))\n",
    "\n",
    "transformed_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(text, lang):\n",
    "    weight_indexes = [three_gram_to_index.get(three_gram, -1) for three_gram in analyze(text)]\n",
    "    weight_indexes = list(filter(lambda x: x != -1, weight_indexes))\n",
    "    return np.sum(transformed_weights[lang,weight_indexes])\n",
    "\n",
    "adjustment = np.asarray([\n",
    "    score(corpus_raw[i], i)/len(analyze(corpus_raw[i]))\n",
    "    for i,lang in enumerate(languages)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scoresV2(text):\n",
    "    weight_indexes_all = [three_gram_to_index.get(three_gram, -1) for three_gram in analyze(text)]\n",
    "    weight_indexes_filtered = list(filter(lambda x: x != -1, weight_indexes_all))\n",
    "    out = np.sum(transformed_weights[:, weight_indexes_filtered], axis=1).T/adjustment\n",
    "    lang = languages[np.argmax(out)]\n",
    "    return lang, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right: 2999, wrong: 2, er: 0.06664445184938354%\n",
      "right: 5999, wrong: 2, er: 0.03332777870354941%\n",
      "right: 8999, wrong: 2, er: 0.022219753360737695%\n",
      "right: 11999, wrong: 2, er: 0.016665277893508874%\n",
      "right: 14998, wrong: 3, er: 0.01999866675554963%\n",
      "right: 17997, wrong: 4, er: 0.022220987722904283%\n",
      "right: 20995, wrong: 6, er: 0.02857006809199562%\n",
      "Final er: 0.02857006809199562%\n"
     ]
    }
   ],
   "source": [
    "right = 1\n",
    "wrong = []\n",
    "def run_tests():\n",
    "    global right, wrong\n",
    "    tests = open('europarl.test')\n",
    "    for x in range(100):\n",
    "        try:\n",
    "            for y in range(3000):\n",
    "                line = tests.readline()\n",
    "                [lang, text] = line.split('\\t')\n",
    "                if scoresV2(text)[0] == lang:\n",
    "                    right = right + 1\n",
    "                else:\n",
    "                    wrong.append((line, scoresV2(text), lang))\n",
    "        except:\n",
    "            print(\"Final er: {er}%\".format(er=100*len(wrong)/(right+len(wrong))))\n",
    "            break\n",
    "        print(\n",
    "            \"right: {right}, wrong: {wrong}, er: {er}%\".format(\n",
    "                right=right, wrong=len(wrong),er = 100*len(wrong)/(right+len(wrong))\n",
    "            )\n",
    "        )\n",
    "run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cs\\tDnes myslím na nás, tedy na vás a na sebe.\\n',\n",
       "  ('sk', matrix([[  0.94641063,   1.68830936,   1.69163511,   1.7416031 ,\n",
       "              3.41941703,   2.21683045,   2.64472688,   3.46579837,\n",
       "              1.94570638,   1.5250961 ,   1.65197466,   0.51903424,\n",
       "              1.6638313 ,   1.06472754,   4.30951664,  20.45483702,\n",
       "             20.14926049,   7.08688228,   3.7683017 ,   0.35626362,\n",
       "              0.13906134]])),\n",
       "  'cs'),\n",
       " ('da\\tEn nulsats er et specifikt tal.\\n',\n",
       "  ('sv', matrix([[ 11.89867942,  11.22638711,   2.9597506 ,   7.49570511,\n",
       "              6.30079046,   6.45321667,   6.49040505,   5.33730654,\n",
       "              6.39321838,   5.69665483,   4.98277098,   1.57433674,\n",
       "              5.37249249,   4.93929535,   1.98375557,   4.61579446,\n",
       "              4.36026103,   3.05217109,   4.42623671,   0.90414241,\n",
       "              0.18904887]])),\n",
       "  'da'),\n",
       " ('lv\\tEs runāju par Banco Português de Negócios un Banco Privado Português.\\n',\n",
       "  ('pt', matrix([[  9.75346054,  10.1594535 ,   8.56723148,   9.57290345,\n",
       "             14.22906177,  13.08078981,  27.86510503,  39.50719462,\n",
       "             18.05953091,  16.53216309,   9.52162616,   6.37572017,\n",
       "             12.97828044,  19.41766736,   8.3752926 ,  10.36544183,\n",
       "             10.13401377,  11.62561806,   7.40314527,   2.0885551 ,\n",
       "              1.63316277]])),\n",
       "  'lv'),\n",
       " ('pl\\tRegiony te to belgijski region Limburg, holenderski region Limburg i region Aachen.\\n',\n",
       "  ('en', matrix([[ 25.7461998 ,  26.0517097 ,  25.33576219,  24.42863628,\n",
       "             32.57569774,  17.86661217,  21.37184065,  23.46464922,\n",
       "             24.77940314,  25.0240137 ,  16.2870061 ,  11.50195193,\n",
       "             18.95844384,   9.18413601,  22.24155028,  17.52643343,\n",
       "             18.53737643,  19.54578973,  12.9725893 ,   2.43315487,   1.4739284 ]])),\n",
       "  'pl'),\n",
       " ('sk\\tJe to také jednoduché.\\n',\n",
       "  ('cs', matrix([[  0.73977882,   1.51522733,   0.99892864,   1.39670388,\n",
       "              3.21307185,   2.67482359,   1.06506026,   0.35053272,\n",
       "              0.92193139,   0.99881228,   0.4411431 ,   0.41181161,\n",
       "              0.8586403 ,   0.79488483,   5.14853157,  12.14259446,\n",
       "             12.55407961,   4.31800552,   0.72826268,   0.        ,   0.0427289 ]])),\n",
       "  'sk'),\n",
       " ('sl\\tTo je recept za katastrofo.\\n',\n",
       "  ('sk',\n",
       "   matrix([[ 5.31138891,  6.21988662,  5.14053048,  5.23767961,  7.40427673,\n",
       "             8.01244477,  6.64466991,  6.00164588,  6.54844334,  5.93535549,\n",
       "             3.85830015,  3.47608694,  4.73544354,  6.4239925 ,  6.84371598,\n",
       "             9.05513591,  8.99654196,  8.89014355,  3.08056112,  0.47393237,\n",
       "             0.10767495]])),\n",
       "  'sl')]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ro',\n",
       " matrix([[ 1.05385201,  0.72462437,  0.14895756,  0.18375937,  0.65581083,\n",
       "           1.41197319,  0.6840087 ,  1.80449495,  1.2374858 ,  2.42291788,\n",
       "           0.53790615,  0.12335426,  0.18238501,  0.15614746,  0.15169113,\n",
       "           0.38689419,  0.79227191,  1.44413119,  0.40337961,  0.08271628,\n",
       "           0.07205493]]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoresV2(\"Avem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.15873984,  1.31119353,  5.37525219, ...,  1.        ,\n",
       "        1.        ,  1.        ])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Coconut (Python 3)",
   "language": "coconut",
   "name": "coconut3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3.6
   },
   "file_extension": ".coco",
   "mimetype": "text/x-python3",
   "name": "coconut",
   "pygments_lexer": "coconut"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
