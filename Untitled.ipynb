{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tests import en_test_inputs, fr_test_ins, it_test_ins, lv_test_ins\n",
    "import re\n",
    "%matplotlib inline\n",
    "\n",
    "# Size of traning data to be read in bytes\n",
    "TRAINING_DATA_SIZE = 2000000\n",
    "\n",
    "languages = [\n",
    "    'sv', 'da', 'de', 'nl', 'en', 'fr', 'es', 'pt', 'it', 'ro', 'et',\n",
    "    'fi','lt', 'lv', 'pl', 'sk', 'cs', 'sl', 'hu', 'bg',  'el'\n",
    "]\n",
    "\n",
    "files = [\n",
    "    \"train/europarl-v7.{lang}-en.{lang}\".format(lang=x)\n",
    "    for x in languages\n",
    "]\n",
    "\n",
    "corpus_raw = [\n",
    "    open(x).read(TRAINING_DATA_SIZE)\n",
    "    for x in files\n",
    "]\n",
    "\n",
    "corpus = [\n",
    "    re.sub(r'[?‚Äù_\"%()!--+,:;./\\]\\[\\xad\\n0-9\\=<>]', '', x)\n",
    "    for x in corpus_raw\n",
    "]\n",
    "\n",
    "count_vectorizer = CountVectorizer(ngram_range=(4, 4), analyzer='char_wb')\n",
    "analyze = count_vectorizer.build_analyzer()\n",
    "counts = count_vectorizer.fit_transform(corpus)\n",
    "\n",
    "normalized_counts = counts/(counts.mean(axis=1)*counts.sum(axis=0))\n",
    "normalized_counts = normalized_counts/normalized_counts.mean()\n",
    "transformed_weights = np.log10(normalized_counts + 1)\n",
    "\n",
    "word_to_weights = {\n",
    "    key: i\n",
    "    for i, key in enumerate(count_vectorizer.get_feature_names())\n",
    "}\n",
    "\n",
    "def scoresV2(text):\n",
    "    weight_indexes_all = [\n",
    "        word_to_weights.get(word, -1)\n",
    "        for word in analyze(text)\n",
    "    ]\n",
    "    weight_indexes_filtered = list(filter(lambda x: x != -1, weight_indexes_all))\n",
    "    weights = np.sum(transformed_weights[:, weight_indexes_filtered], axis=1)\n",
    "    lang = languages[np.argmax(weights)]\n",
    "    return lang, weights\n",
    "\n",
    "def run_tests():\n",
    "    right = 0\n",
    "    wrong = 0\n",
    "    tests = open('europarl.test')\n",
    "    for x in range(TRAINING_DATA_SIZE):\n",
    "        line = tests.readline()\n",
    "        if line == '':\n",
    "            print(\"Final er: {er}%\".format(er=100*wrong/(right+wrong)))\n",
    "            return\n",
    "        [lang, text] = line.split('\\t')\n",
    "        if scoresV2(text)[0] == lang:\n",
    "            right = right + 1\n",
    "        else:\n",
    "            wrong = wrong + 1\n",
    "run_tests()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Coconut (Python 3)",
   "language": "coconut",
   "name": "coconut3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3.6
   },
   "file_extension": ".coco",
   "mimetype": "text/x-python3",
   "name": "coconut",
   "pygments_lexer": "coconut"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
